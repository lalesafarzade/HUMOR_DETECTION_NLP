{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import optimize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from scipy.io import loadmat\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import data_splitter,text_process,build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test,train_lab,test_lab = data_splitter('resources/dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(X_train, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    m = x.shape[0]\n",
    "    for i in range(0, num_iters):\n",
    "    \n",
    "        z = np.dot(x,theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))    \n",
    "\n",
    "        theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
    "        \n",
    "  \n",
    "    J = float(J)\n",
    "    return J, theta\n",
    "\n",
    "\n",
    "def extract_features(text, freqs):\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1\n",
    "    word_l = text_process(text)\n",
    "    for word in word_l:\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.49099771.\n",
      "The resulting vector of weights is [-6e-08, 0.00031954, -0.00038018]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(X_train), 3))\n",
    "for i in range(len(X_train)):\n",
    "    X[i, :]= extract_features(X_train[i], freqs)\n",
    "J, theta = gradientDescent(X, y_train, np.zeros((3, 1)), 1e-9, 1500)\n",
    "\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, freqs, theta):\n",
    "    x = extract_features(text,freqs)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    y_hat = []\n",
    "    for text in test_x:\n",
    "        y_pred = predict_text(text, freqs, theta)\n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "            \n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.8238\n"
     ]
    }
   ],
   "source": [
    "y_hat = test_logistic_regression(X_test, y_test, freqs, theta)\n",
    "accuracy = (y_hat==np.squeeze(y_test)).sum()/len(X_test)\n",
    "print(f\"Logistic regression model's accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.80      0.82     20000\n",
      "         1.0       0.81      0.85      0.83     20000\n",
      "\n",
      "    accuracy                           0.82     40000\n",
      "   macro avg       0.82      0.82      0.82     40000\n",
      "weighted avg       0.82      0.82      0.82     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89242283]]\n",
      "Humor text\n"
     ]
    }
   ],
   "source": [
    "my_text =\"What do you call a bee that canâ€™t make up its mind? A maybe.\"\n",
    "y_hat = predict_text(my_text, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Humor text')\n",
    "else: \n",
    "    print('Non_Humor text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4919507]]\n",
      "Non_Humor text\n"
     ]
    }
   ],
   "source": [
    "my_text =\"I miss you\"\n",
    "y_hat = predict_text(my_text, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Humor text')\n",
    "else: \n",
    "    print('Non_Humor text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('resources/dataset.csv')\n",
    "X_train, X_test, y_train, y_test=train_test_split(df['text'], df['humor'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "('classifier', GridSearchCV(LogisticRegression(),param_grid={'C': np.logspace(-3,3,6),'max_iter':[10,100,500], \"penalty\":[\"l1\",\"l2\"]} ,refit=True,verbose=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END ....C=0.001, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.001, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.001, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.001, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.001, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, max_iter=10, penalty=l2;, score=0.834 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.001, max_iter=10, penalty=l2;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, max_iter=10, penalty=l2;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.001, max_iter=10, penalty=l2;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, max_iter=10, penalty=l2;, score=0.832 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.001, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, max_iter=100, penalty=l2;, score=0.834 total time=   0.1s\n",
      "[CV 2/5] END .C=0.001, max_iter=100, penalty=l2;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END .C=0.001, max_iter=100, penalty=l2;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .C=0.001, max_iter=100, penalty=l2;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, max_iter=100, penalty=l2;, score=0.832 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.001, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, max_iter=500, penalty=l2;, score=0.834 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, max_iter=500, penalty=l2;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END .C=0.001, max_iter=500, penalty=l2;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, max_iter=500, penalty=l2;, score=0.831 total time=   0.1s\n",
      "[CV 5/5] END .C=0.001, max_iter=500, penalty=l2;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=10, penalty=l2;, score=0.852 total time=   0.1s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=10, penalty=l2;, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=10, penalty=l2;, score=0.853 total time=   0.1s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=10, penalty=l2;, score=0.849 total time=   0.1s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=10, penalty=l2;, score=0.852 total time=   0.1s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=100, penalty=l2;, score=0.853 total time=   0.5s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=100, penalty=l2;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=100, penalty=l2;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=100, penalty=l2;, score=0.850 total time=   0.4s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=100, penalty=l2;, score=0.853 total time=   0.4s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.015848931924611134, max_iter=500, penalty=l2;, score=0.853 total time=   0.4s\n",
      "[CV 2/5] END C=0.015848931924611134, max_iter=500, penalty=l2;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END C=0.015848931924611134, max_iter=500, penalty=l2;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END C=0.015848931924611134, max_iter=500, penalty=l2;, score=0.850 total time=   0.4s\n",
      "[CV 5/5] END C=0.015848931924611134, max_iter=500, penalty=l2;, score=0.853 total time=   0.4s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=10, penalty=l2;, score=0.857 total time=   0.1s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=10, penalty=l2;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=10, penalty=l2;, score=0.859 total time=   0.1s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=10, penalty=l2;, score=0.855 total time=   0.1s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=10, penalty=l2;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=100, penalty=l2;, score=0.887 total time=   1.2s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=100, penalty=l2;, score=0.889 total time=   1.2s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=100, penalty=l2;, score=0.890 total time=   1.2s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=100, penalty=l2;, score=0.887 total time=   1.4s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=100, penalty=l2;, score=0.888 total time=   1.3s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.25118864315095796, max_iter=500, penalty=l2;, score=0.887 total time=   1.1s\n",
      "[CV 2/5] END C=0.25118864315095796, max_iter=500, penalty=l2;, score=0.889 total time=   1.2s\n",
      "[CV 3/5] END C=0.25118864315095796, max_iter=500, penalty=l2;, score=0.890 total time=   1.3s\n",
      "[CV 4/5] END C=0.25118864315095796, max_iter=500, penalty=l2;, score=0.887 total time=   1.3s\n",
      "[CV 5/5] END C=0.25118864315095796, max_iter=500, penalty=l2;, score=0.888 total time=   1.2s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=10, penalty=l2;, score=0.863 total time=   0.1s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=10, penalty=l2;, score=0.866 total time=   0.1s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=10, penalty=l2;, score=0.866 total time=   0.1s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=10, penalty=l2;, score=0.861 total time=   0.1s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=10, penalty=l2;, score=0.865 total time=   0.1s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=100, penalty=l2;, score=0.903 total time=   1.6s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=100, penalty=l2;, score=0.903 total time=   1.6s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=100, penalty=l2;, score=0.903 total time=   1.7s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=100, penalty=l2;, score=0.900 total time=   1.4s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=100, penalty=l2;, score=0.903 total time=   1.6s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.981071705534969, max_iter=500, penalty=l2;, score=0.903 total time=   3.7s\n",
      "[CV 2/5] END C=3.981071705534969, max_iter=500, penalty=l2;, score=0.904 total time=   4.1s\n",
      "[CV 3/5] END C=3.981071705534969, max_iter=500, penalty=l2;, score=0.903 total time=   4.1s\n",
      "[CV 4/5] END C=3.981071705534969, max_iter=500, penalty=l2;, score=0.900 total time=   4.2s\n",
      "[CV 5/5] END C=3.981071705534969, max_iter=500, penalty=l2;, score=0.903 total time=   4.6s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=10, penalty=l2;, score=0.864 total time=   0.1s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=10, penalty=l2;, score=0.868 total time=   0.1s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=10, penalty=l2;, score=0.867 total time=   0.1s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=10, penalty=l2;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=10, penalty=l2;, score=0.866 total time=   0.2s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=100, penalty=l2;, score=0.898 total time=   1.9s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=100, penalty=l2;, score=0.896 total time=   1.7s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=100, penalty=l2;, score=0.897 total time=   1.7s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=100, penalty=l2;, score=0.894 total time=   1.7s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=100, penalty=l2;, score=0.898 total time=   1.7s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=63.0957344480193, max_iter=500, penalty=l2;, score=0.895 total time=   8.5s\n",
      "[CV 2/5] END C=63.0957344480193, max_iter=500, penalty=l2;, score=0.896 total time=   8.4s\n",
      "[CV 3/5] END C=63.0957344480193, max_iter=500, penalty=l2;, score=0.896 total time=   8.9s\n",
      "[CV 4/5] END C=63.0957344480193, max_iter=500, penalty=l2;, score=0.895 total time=   8.4s\n",
      "[CV 5/5] END C=63.0957344480193, max_iter=500, penalty=l2;, score=0.898 total time=   8.3s\n",
      "[CV 1/5] END ...C=1000.0, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=1000.0, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=1000.0, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=1000.0, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=1000.0, max_iter=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=1000.0, max_iter=10, penalty=l2;, score=0.864 total time=   0.1s\n",
      "[CV 2/5] END .C=1000.0, max_iter=10, penalty=l2;, score=0.868 total time=   0.2s\n",
      "[CV 3/5] END .C=1000.0, max_iter=10, penalty=l2;, score=0.867 total time=   0.1s\n",
      "[CV 4/5] END .C=1000.0, max_iter=10, penalty=l2;, score=0.863 total time=   0.1s\n",
      "[CV 5/5] END .C=1000.0, max_iter=10, penalty=l2;, score=0.866 total time=   0.1s\n",
      "[CV 1/5] END ..C=1000.0, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=1000.0, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=1000.0, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=1000.0, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=1000.0, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, max_iter=100, penalty=l2;, score=0.888 total time=   1.6s\n",
      "[CV 2/5] END C=1000.0, max_iter=100, penalty=l2;, score=0.887 total time=   1.6s\n",
      "[CV 3/5] END C=1000.0, max_iter=100, penalty=l2;, score=0.886 total time=   1.5s\n",
      "[CV 4/5] END C=1000.0, max_iter=100, penalty=l2;, score=0.890 total time=   1.5s\n",
      "[CV 5/5] END C=1000.0, max_iter=100, penalty=l2;, score=0.894 total time=   1.7s\n",
      "[CV 1/5] END ..C=1000.0, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=1000.0, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=1000.0, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=1000.0, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=1000.0, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1000.0, max_iter=500, penalty=l2;, score=0.883 total time=   8.2s\n",
      "[CV 2/5] END C=1000.0, max_iter=500, penalty=l2;, score=0.884 total time=   8.2s\n",
      "[CV 3/5] END C=1000.0, max_iter=500, penalty=l2;, score=0.883 total time=   8.2s\n",
      "[CV 4/5] END C=1000.0, max_iter=500, penalty=l2;, score=0.881 total time=   8.6s\n",
      "[CV 5/5] END C=1000.0, max_iter=500, penalty=l2;, score=0.886 total time=   8.5s\n"
     ]
    }
   ],
   "source": [
    "rf_model=pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.90      0.91     20070\n",
      "        True       0.90      0.91      0.90     19930\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    #print(conf_mat)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(2), range(2))\n",
    "    plt.xticks(range(2), range(2))\n",
    "    plt.colorbar();\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(i-0.2,j+0.1, str(conf_mat[j, i]), color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.880 total time=20.3min\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time=20.4min\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', GridSearchCV(SVC(),param_grid={'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001],\n",
    "                                                  'kernel': [\"rbf\",'sigmoid']} ,refit=True,verbose=3))\n",
    "])\n",
    "\n",
    "svm_model=pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm_model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "plot_confusion_matrix(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d8252e6ff2fcf763984e1fe66594d90dbe24607a75b4fe465f6934f23ce49e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
