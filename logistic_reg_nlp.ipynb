{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import optimize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from scipy.io import loadmat\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import data_splitter,text_process,build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "humor_df=df[df['humor']==True]\n",
    "non_humor_df=df[df['humor']==False]\n",
    "test_pos = humor_df[:20000]\n",
    "train_pos = humor_df[20000:]\n",
    "test_neg = non_humor_df[:20000]\n",
    "train_neg = non_humor_df[20000:]\n",
    "test=pd.concat([test_pos,test_neg])\n",
    "train=pd.concat([train_pos,train_neg])\n",
    "X_train=list(train['text'])\n",
    "X_train=list(test['text'])\n",
    "y_train=list(train['humor'].map({True:1,False:0}))\n",
    "y_test=list(test['humor'].map({True:1,False:0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test,train_lab,test_lab = data_splitter('dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(X_train, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    m = x.shape[0]\n",
    "    for i in range(0, num_iters):\n",
    "    \n",
    "        z = np.dot(x,theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))    \n",
    "\n",
    "        theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
    "        \n",
    "  \n",
    "    J = float(J)\n",
    "    return J, theta\n",
    "\n",
    "\n",
    "def extract_features(text, freqs):\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1\n",
    "    word_l = text_process(text)\n",
    "    for word in word_l:\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.49099771.\n",
      "The resulting vector of weights is [-6e-08, 0.00031954, -0.00038018]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(X_train), 3))\n",
    "for i in range(len(X_train)):\n",
    "    X[i, :]= extract_features(X_train[i], freqs)\n",
    "J, theta = gradientDescent(X, y_train, np.zeros((3, 1)), 1e-9, 1500)\n",
    "\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, freqs, theta):\n",
    "    x = extract_features(text,freqs)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89242283]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_text(\"What do you call a bee that can’t make up its mind? A maybe.\", freqs, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    y_hat = []\n",
    "    for text in test_x:\n",
    "        y_pred = predict_text(text, freqs, theta)\n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "            \n",
    "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.8238\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(X_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89242283]]\n",
      "Humor text\n"
     ]
    }
   ],
   "source": [
    "my_text =\"What do you call a bee that can’t make up its mind? A maybe.\"\n",
    "y_hat = predict_text(my_text, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Humor text')\n",
    "else: \n",
    "    print('Non_Humor text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4919507]]\n",
      "Non_Humor text\n"
     ]
    }
   ],
   "source": [
    "my_text =\"I miss you\"\n",
    "y_hat = predict_text(my_text, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Humor text')\n",
    "else: \n",
    "    print('Non_Humor text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', GridSearchCV(SVC(),param_grid={'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001],\n",
    "                                                  'kernel': ['sigmoid']} ,refit=True,verbose=3))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d8252e6ff2fcf763984e1fe66594d90dbe24607a75b4fe465f6934f23ce49e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
